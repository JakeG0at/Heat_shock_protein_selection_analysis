{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the hsp.tsv file\n",
    "path = '/home/jake/Downloads/Salmo_Project/'\n",
    "hsp = os.listdir(f\"{path}heatshock_proteins\")\n",
    "not_hsps_sample = os.listdir(f\"{path}/not_heatshock_proteins_control_group\")\n",
    "Orthogroups = f'{path}Orthogroups/'\n",
    "Orthogroups = pd.read_csv(f'{Orthogroups}Orthogroups.tsv', sep = '\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to add the species name to all of the fasta headers :(\n",
    "\n",
    "def parse_fasta_to_df(file):\n",
    "    fasta_list = []\n",
    "    current_header = None\n",
    "    current_sequence = \"\"\n",
    "    with open(file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\">\"):\n",
    "                if current_header:\n",
    "                    fasta_list.append([current_header, current_sequence])\n",
    "                current_header = line[1:]\n",
    "                current_sequence = \"\"\n",
    "            else:\n",
    "                current_sequence += line.strip()\n",
    "    return pd.DataFrame(fasta_list, columns=['header', 'sequence'])\n",
    "\n",
    "\n",
    "def fix_headers(df):\n",
    "    df['new_head'] = df['Species'] + \"_\" + df['header']\n",
    "# Make a new data frame that has only the new_head and sequence columns\n",
    "    df = df[['new_head', 'sequence']]\n",
    "    with open('/home/jake/Downloads/OG0000151_modified.fasta', 'w') as f:\n",
    "        for i, row in dfx.iterrows():\n",
    "            header = row['new_head']\n",
    "            sequence = row['sequence']\n",
    "            f.write(f\">{header}\\n{sequence}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a filtered dataframe of orthogroups that has the column names of orthogroups and only one row that does not have any Nan values\n",
    "filtered = Orthogroups.dropna(axis=1, how='all')\n",
    "filtered = filtered.dropna(axis=0, how='any')\n",
    "#Keep only the headers and the first row\n",
    "filtered = filtered.iloc[0:1, 0:]\n",
    "#Drop the values after the first ,\n",
    "filtered = filtered.applymap(lambda x: x.split(',')[0])\n",
    "filtered = filtered.applymap(lambda x: x.split('G0')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Danio_rerio': 'ENSDAR',\n",
       " 'Hucho_hucho': 'ENSHHU',\n",
       " 'Oncorhynchus_kisutch': 'ENSOKI',\n",
       " 'Oncorhynchus_mykiss': 'ENSOMY',\n",
       " 'Oncorhynchus_tshawytscha': 'ENSOTS',\n",
       " 'Salmo_salar': 'ENSSSA',\n",
       " 'Salmo_trutta': 'ENSSTU'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop the index\n",
    "filtered = filtered.reset_index(drop=True)\n",
    "#createa a dicionary with colnames as key: and the values as the orthogroup\n",
    "filtered_dict = filtered.to_dict('records')[0]\n",
    "filtered_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderpath = '/home/jake/Downloads/Salmo_Project/heatshock_proteins/'\n",
    "\n",
    "# Loop through every file in the folder\n",
    "for filename in os.listdir(folderpath):\n",
    "    # If the file is a fasta file, process it\n",
    "    if filename.endswith('.fa'):\n",
    "        # Open the file and read its contents\n",
    "        with open(os.path.join(folderpath, filename), 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        # Loop through every line in the file\n",
    "        for i in range(len(lines)):\n",
    "            line = lines[i].strip()\n",
    "            # If the line is a header, process it\n",
    "            if line.startswith('>'):\n",
    "                # Check if the header starts with any value in the filtered_dict\n",
    "                for key, value in filtered_dict.items():\n",
    "                    if value in line:\n",
    "                        # If it does, append the corresponding key to the start of the header with an underscore\n",
    "                        new_header = f'>{key}_{line[1:]}'\n",
    "                        # Replace the old header with the new header in the lines list\n",
    "                        lines[i] = new_header + '\\n'\n",
    "                        break\n",
    "        # Write the modified contents back to the file\n",
    "        with open(os.path.join(folderpath, filename), 'w') as f:\n",
    "            f.writelines(lines)\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
